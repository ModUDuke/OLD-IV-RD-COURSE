--- 
title       : "RDD as Causality: Introduction to Regression Discontinuity Design"
description : "This chapter will introduce you to regression discontinuity design (RDD)"
 
# Notes:
#--------------
# Ask MC about what an RD is
# Ask MC about key variables in RDD's
# Deciding what constitutes "close" to the cutoff
#  - want to increase BW to get more data
#  - want to decrease BW to remove confounding bias
# Nonparametric (local linear) vs. parametric (separate regressions)
# Balance checks (McCrary test, etc.)
# RD as DID
# Sharp vs. Fuzzy: how do you know it's not fuzzy? outcome variable is either 0 or 1


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:efc08cc323
## Regression Discontinuity: Looking at People on the Edge
*** =video_link
//player.vimeo.com/video/218501284


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:f401e635a5
## Key variables in an RD design
Which of the following variables is *not* a key (required) variable in a regression discontinuity design?

*** =instructions
- Outcome variable
- Control variable
- Treatment variable
- Running variable
*** =sct
```{r}
msg1 = "The outcome variable is the variable of interest. Try again"
msg2 = "Correct! While most RD's use at least one control variable, doing so is not strictly necessary for RD analysis. (i.e. it is possible, but not common, to run an RD without any control variables.)"
msg3 = "The treatment variable is necessary in order to estimate any kind of causal effect. Try again"
msg4 = "The running variable is how the researcher divides the sample into treatment and control groups. Try again"
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:79965f29b5
## Regression Discontinuity: More Analysis of Thistlethwaite and Campbell
*** =video_link
//player.vimeo.com/video/218502333


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:7977c48f95
## Practice identifying key variables in an RD design
A pair of researchers named Jonah Berger and Devin Pope recently published a study that found that losing can lead to winning. As part of the study, the researchers documented this phenomenon in National Basketball Association (NBA) games. The researchers studied thousands of NBA game outcomes and found that teams that were just behind at halftime were more likely to win the game, after controling for other important factors (like the winning percentage of each team). 

In this study, which variable is the outcome variable, which is the running variable, and which is the treatment variable?

*** =instructions
- The score at halftime is the outcome variable, winning the game is the running variable, and the home team losing at halftime is the treatment variable.
- Winning the game is the outcome variable, the home team losing at halftime is the running variable, and the score at halftime is the treatment variable.
- The score at halftime is the outcome variable, the home team losing at halftime is the running variable, and winning the game is the treatment variable.
- Winning the game is the outcome variable, the score at halftime is the running variable, and the home team losing at halftime is the treatment variable.
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Try again"
msg3 = "Try again"
msg4 = "Correct!"
test_mc(correct = 4, feedback_msgs = c(msg1,msg2,msg3,msg4))
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:1a5dfd94ba
## How to Compute Causal Effects in a Regression Discontinuity Analysis
*** =video_link
//player.vimeo.com/video/218502963



--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:8dfb92fd8e
## Practice Computing Regression Discontinuity Effects
Let's continue with the NBA research example. On your workspace is a simulated data set, called `NBA`, that closely resembles the data analyzed by Berger and Pope. The data frame `NBA` contains game characteristics for over 18,000 NBA games between 1994 and 2009.

The outcome variable we are interested in is called `home.team.final.margin`, which is the final margin of victory (or loss) for the home team. The running variable in this RDD is called `home.team.halftime.margin`, or the margin of victory (or loss) for the home team at halftime. We define treatment as the home team being ahead at halftime, i.e. `home.team.halftime.margin > 0`. (You can also define it as the home team being behind at halftime and you will get the same results, just opposite sign.)

In this exercise, you will compute the treatment effect of being ahead at halftime on the final margin of victory. You will use regression methods as well as nonparametric methods to assess how robust the effect is.

*** =instructions
- Use OLS regression to estimate the treatment effect of being behind at halftime on the final margin of victory under two different parametric scenarios
- Estimate the treatment effect using non-parametric methods

*** =pre_exercise_code
```{r}
# require(rdd)

set.seed(1)
n <- 18060

# Initialize dataframe
NBA <- as.data.frame(matrix(0, ncol=10,nrow=n))
colnames(NBA) <- c("id","season","home.team","away.team","home.team.qual","away.team.qual","home.team.halftime.score","away.team.halftime.score","home.team.final.margin","home.team.win")

# Simulate baseline data
NBA$id         <- seq(1,n,1)
NBA$season     <- ifelse(NBA$id %in% seq( 0*1204+1, 1*1204,1),1994,
                  ifelse(NBA$id %in% seq( 1*1204+1, 2*1204,1),1995,
                  ifelse(NBA$id %in% seq( 2*1204+1, 3*1204,1),1996,
                  ifelse(NBA$id %in% seq( 3*1204+1, 4*1204,1),1997,
                  ifelse(NBA$id %in% seq( 4*1204+1, 5*1204,1),1998,
                  ifelse(NBA$id %in% seq( 5*1204+1, 6*1204,1),1999,
                  ifelse(NBA$id %in% seq( 6*1204+1, 7*1204,1),2000,
                  ifelse(NBA$id %in% seq( 7*1204+1, 8*1204,1),2001,
                  ifelse(NBA$id %in% seq( 8*1204+1, 9*1204,1),2002,
                  ifelse(NBA$id %in% seq( 9*1204+1,10*1204,1),2003,
                  ifelse(NBA$id %in% seq(10*1204+1,11*1204,1),2004,
                  ifelse(NBA$id %in% seq(11*1204+1,12*1204,1),2005,
                  ifelse(NBA$id %in% seq(12*1204+1,13*1204,1),2006,
                  ifelse(NBA$id %in% seq(13*1204+1,14*1204,1),2007,
                  ifelse(NBA$id %in% seq(14*1204+1,15*1204,1),2008,0)))))))))))))))
teamqual <- cbind(c("BOS","NJN","NYK","PHL","GSW","LAC","LAL","PHX","SAC","CHI","CLE","DET","IND","MIL","DAL","HOU","MEM","SAS","ATL","CHA","MIA","ORL","WSH","DEN","MIN","SEA","POR","UTA"),
                  matrix(rnorm(28*15,mean=0,sd=1), ncol=15))
NBA$home.team      <- sample(teamqual[,1],n,replace=TRUE)
NBA$away.team      <- sample(teamqual[,1],n,replace=TRUE)
print(paste0('Number of teams playing themselves: ',sum(NBA$home.team==NBA$away.team)/n*100,'%'))
for (i in 1:n) {
    if (NBA$home.team[i]==NBA$away.team[i]) {
        NBA$away.team[i] <- sample(setdiff(teamqual[,1],NBA$home.team[i]),1)
    }
}
print(paste0('Number of teams playing themselves: ',sum(NBA$home.team==NBA$away.team)/n*100,'%'))

# generate team qualities to explain outcomes for each game
for (i in 1:n) {
    NBA$away.team.qual[i] <- as.numeric(teamqual[teamqual[,1]==NBA$away.team[i],NBA$season[i]-1992])
    NBA$home.team.qual[i] <- as.numeric(teamqual[teamqual[,1]==NBA$home.team[i],NBA$season[i]-1992])
}

NBA$home.team <- as.factor(NBA$home.team)
NBA$away.team <- as.factor(NBA$away.team)

# Generate halftime scores
NBA$home.team.halftime.score  <- round(NBA$home.team.qual+rnorm(n, mean=48, sd=4), digits=0)
NBA$away.team.halftime.score  <- round(NBA$away.team.qual+rnorm(n, mean=47, sd=6), digits=0)
NBA$home.team.halftime.margin <- NBA$home.team.halftime.score - NBA$away.team.halftime.score

# Remove games that are tied at halftime
print(dim(NBA))
NBA <- NBA[NBA$home.team.halftime.margin!=0,]
print(dim(NBA))
n1 <- dim(NBA)[1]

# Generate final score
NBA$home.team.winning.at.half <- NBA$home.team.halftime.margin>0
NBA$home.team.final.margin    <- round(2 - 5*NBA$home.team.winning.at.half + 2*NBA$home.team.halftime.margin -.05*NBA$home.team.halftime.margin^2 + NBA$home.team.qual - NBA$away.team.qual + rnorm(n1, mean=0, sd=10), digits=0)
NBA$home.team.win             <- NBA$home.team.final.margin>0

# Clean up data
NBA$season <- as.factor(NBA$season)
NBA <- NBA[,c("id","season","home.team","away.team","home.team.qual","away.team.qual","home.team.halftime.margin","home.team.final.margin","home.team.winning.at.half","home.team.win")]

    
```
*** =sample_code
```{r}
# Before running a regression model, let's examine the data
    str(NBA)

# The dataset contains eight variables: a game identifier, a season identifier, two team identifiers (for home and visitor), the quality of the home and visiting teams (a normalized verison of win percentage), and the halftime and end-of-game margins of victory for the home team.

# Create a dummy variable that equals 1 if the home team is ahead at halftime
#---- Question 1-------------------------------------#
      Solution1<-()
      NBA$home.team.winning.at.half <- Solution1
#----------------------------------------------------#
  
# Use the lm function to compute the RD estimate of being ahead at halftime on the final margin of victory. Include the following as additional controls in the regression: home team's halftime margin, home team quality, and away team quality.

#---- Question 2-------------------------------------#
      Solution2<-summary(lm())
#----------------------------------------------------#

# As mentioned in earlier videos, there may be a non-linear effect of the halftime margin on the final margin. In the previous question, we assumed the relationship was linear. In the next question, we will relax this assumption.

# In Question 3, estimate the same regression as in Question 2, but this time include a quadratic effect of halftime margin on the final margin. This is done by adding I(home.team.halftime.margin^2) as an additional term in the model statement of lm.

#---- Question 3-------------------------------------#
      Solution3<-summary(lm())
#----------------------------------------------------#
  
# As a last exercise, let's further relax the quadratic assumption of halftime margin. Instead of estimating an OLS regression using the lm function, we will now use a package called 'rdd' which allows us to examine how sensitive the regression assumptions are for our RD estimate.

# The function we will use is called RDestimate. Without getting into too many details, copy and paste the following syntax as your answer to Question 4: summary(RDestimate(home.team.final.margin ~ home.team.halftime.margin | home.team.qual+away.team.qual,data=NBA))


# Now compare the results of our three causal effect estimates. Which estimate do you think most closely captures the true causal effect of being behind (or ahead) at halftime on the final margin of victory?

```
*** =solution
```{r}
    Solution1<- NBA$home.team.halftime.margin<0
    Solution2<-summary(lm(home.team.final.margin ~ home.team.winning.at.half+home.team.halftime.margin+home.team.qual+away.team.qual,data=NBA))
    Solution3<-summary(lm(home.team.final.margin ~ home.team.winning.at.half+home.team.halftime.margin+I(home.team.halftime.margin^2)+home.team.qual+away.team.qual,data=NBA))
```
*** =sct
```{r}
test_object("Solution1")
test_object("Solution2")
test_object("Solution3")
success_msg("Good work! From the looks of it, the quadratic specification of halftime margin looks very similar to the nonparametric estimate (4.8 points versus 4.4 points). The linear specification seems to not capture the true relationship between halftime margin and final margin, as it only estimates an effect of 2.5 points.")
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:5a2a1cae28
## Using RDD to Study Neighborhoods and Schools
*** =video_link
//player.vimeo.com/video/218503634



--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:da321f7194
## Thinking about confounders in an RD design
Suppose your friend says "I don’t believe the results in Black (1999) because she doesn't control for whether there is a public park nearby the house. Having a park nearby increases the value of a house. Also, districts that have high test scores also tend to have more parks. So this test score effect might just be because of this unobserved confounder!"

*** =instructions
- Agree
- Disagree
- Partly agree
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! It's a reasonable point, but the fact that we do NOT have to observe this confounder is precisely the beauty of RDD! When we look only at houses close to the boundary, those houses are close to each other, by definition. Hence they are both close to the park. So, although the park might affect the value of both houses, it should do so equally. Hence any *difference* in house prices cannot be attributed to the park. It must be attributed to the test score difference."
msg3 = "Try again"
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3))
```



--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:2781eb8177
## Using geographical borders more generally in RD designs
True or False: As in the Black (1999) paper, anytime there is a geographical border where treatment changes across the border, we can use RDD analysis to learn the causal effect of treatment.

*** =instructions
- True
- False
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! It is true that geographical borders are *often* used to learn about causal effects via RDD. But this requires that the only thing that's different between units on each side of the border is the treatment! This is often not the case. For example, if you look at country borders, there are often many different variables that change as you cross the border, which means it will be hard or impossible to disentangle the effect of just one of these variables."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```

--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:504416b121
## "Fuzzy" Regression Discontinuity: Addressing Blurry Lines Between Groups
*** =video_link
//player.vimeo.com/video/218504968



--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:43f638d1c1
## Identifying fuzzy and sharp RDDs
Consider the following examples. Which is an example of a fuzzy RDD and which is a sharp RDD?

1. Running variable: Age. Treatment: You become eligible for senior citizen welfare programs once you are 65 are older.

2. Running variable: A region's poverty rate. Treatment: Regions become eligible for Federal assistance once their poverty rate is above a certain cutoff.

3. Running variable: Population. Treatment variable: Number of seats a region gets in government (e.g., number of representatives in the U.S. House of Representatives).

*** =instructions
- All are fuzzy
- (1) and (3) are sharp; (2) is fuzzy
- (1) and (2) are sharp; (3) is fuzzy
- (1) is fuzzy; (2) and (3) are sharp
- (1) and (2) are fuzzy; (3) is sharp
- (1) is sharp; (2) and (3) are fuzzy
- (1) and (3) are fuzzy; (2) is sharp
- All are sharp
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Try again"
msg3 = "Try again"
msg4 = "Try again"
msg5 = "Try again"
msg6 = "Try again"
msg7 = "Try again"
msg8 = "Correct! Often the distinction between sharp and fuzzy hinges on the definition of treatment. For (1) and (2), treatment is defined as **eligibility** rather than takeup. A similar idea explains why (3) is sharp: all regions with a certain population have the same number of representatives allocated."
test_mc(correct = 8, feedback_msgs = c(msg1,msg2,msg3,msg4,msg5,msg6,msg7,msg8))
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:e64dfce37b
## Fuzzy RDD and Swiss Religion: Checking the Numbers
*** =video_link
//player.vimeo.com/video/218505946



